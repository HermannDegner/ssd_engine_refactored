"""
ã€APEX SURVIVOR - SSD Pure Theoreticalç‰ˆ v4ã€‘

v3ã®æ§‹é€ çš„çŸ›ç›¾ã‚’è§£æ±ºã—ã€çœŸã®å‰µç™ºã‚’å®Ÿç¾:

v3ã®å•é¡Œç‚¹:
1. äººæ ¼åˆ¥ifæ–‡ã«ã‚ˆã‚‹ã€Œæ´—ç·´ã•ã‚ŒãŸå¤–éƒ¨ãƒ­ã‚¸ãƒƒã‚¯ã€
2. ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã«ã‚ˆã‚‹æ„å‘³åœ§è¨­å®š
3. ã‚³ã‚¢ã‚¨ãƒ³ã‚¸ãƒ³ã®è·³èºæ©Ÿèƒ½ã®ä¸ä½¿ç”¨

v4ã®é©æ–°:
1. å˜ä¸€ã®å‰µç™ºé–¢æ•°: personalityç„¡é–¢ä¿‚ãªçµ±ä¸€çš„è¡Œå‹•å‰µç™º
2. æ±ç”¨åœ§åŠ›æ¬¡å…ƒ: ssd_pressure_systemã«ã‚ˆã‚‹ç†è«–çš„æ„å‘³åœ§
3. è·³èºçµ±åˆ: detect_leapã«ã‚ˆã‚‹éé€£ç¶šçš„è¡Œå‹•å¤‰åŒ–
4. ç´”ç²‹å†…éƒ¨åŠ›å­¦: E/Îº/R/Theta/è·³èºã®ã¿ã‹ã‚‰è¡Œå‹•æ±ºå®š

ç†è«–çš„ç´”ç²‹æ€§:
- å¤–éƒ¨ãƒ­ã‚¸ãƒƒã‚¯å®Œå…¨æ’é™¤
- SSDã‚³ã‚¢ã‚¨ãƒ³ã‚¸ãƒ³ã®å…¨æ©Ÿèƒ½æ´»ç”¨
- æ±ç”¨åœ§åŠ›ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ
"""

import sys
from pathlib import Path

# ãƒ‘ã‚¹è¨­å®š
parent_path = Path(__file__).parent.parent
sys.path.insert(0, str(parent_path))

import random
import numpy as np

# SSDãƒ•ãƒ«çµ±åˆã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from core import HumanAgent, HumanParams, HumanPressure, HumanLayer
from core import MultidimensionalPressureEngine, PressureDimension, StructuralLayer
from core import create_pressure_engine_for_scenario


# ===== ã‚²ãƒ¼ãƒ è¨­å®š =====
class GameConfig:
    """APEX SURVIVOR ã‚²ãƒ¼ãƒ ãƒ«ãƒ¼ãƒ«ï¼ˆv4: å¤‰æ›´ãªã—ï¼‰"""
    CHOICES = {
        1: {'score': 10, 'crash_rate': 0.05},
        2: {'score': 20, 'crash_rate': 0.10},
        3: {'score': 30, 'crash_rate': 0.15},
        4: {'score': 40, 'crash_rate': 0.20},
        5: {'score': 50, 'crash_rate': 0.25},
        6: {'score': 60, 'crash_rate': 0.35},
        7: {'score': 70, 'crash_rate': 0.45},
        8: {'score': 80, 'crash_rate': 0.55},
        9: {'score': 90, 'crash_rate': 0.65},
        10: {'score': 100, 'crash_rate': 0.75}
    }
    
    STARTING_HP = 3
    MAX_HP = 5
    HP_PURCHASE_COST = 20
    
    SET_RANK_BONUS = {1: 50, 2: 30, 3: 15}


class ApexPressureEngine:
    """Apex Survivorç”¨æ±ç”¨åœ§åŠ›ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        # æ±ç”¨åœ§åŠ›æ¬¡å…ƒã‚’å®šç¾©
        self.pressure_dimensions = {
            "ç”Ÿå­˜è„…å¨": PressureDimension(
                name="ç”Ÿå­˜è„…å¨",
                base_intensity=1.0,
                target_layers={
                    StructuralLayer.PHYSICAL: 0.4,
                    StructuralLayer.BASE: 0.4,
                    StructuralLayer.CORE: 0.1,
                    StructuralLayer.UPPER: 0.1
                }
            ),
            "ç«¶äº‰åœ§åŠ›": PressureDimension(
                name="ç«¶äº‰åœ§åŠ›", 
                base_intensity=1.0,
                target_layers={
                    StructuralLayer.PHYSICAL: 0.0,
                    StructuralLayer.BASE: 0.1,
                    StructuralLayer.CORE: 0.7,
                    StructuralLayer.UPPER: 0.2
                }
            ),
            "æ™‚é–“åˆ‡è¿«": PressureDimension(
                name="æ™‚é–“åˆ‡è¿«",
                base_intensity=1.0,
                target_layers={
                    StructuralLayer.PHYSICAL: 0.2,
                    StructuralLayer.BASE: 0.3,
                    StructuralLayer.CORE: 0.3,
                    StructuralLayer.UPPER: 0.2
                }
            ),
            "æƒ…å ±ä¸è¶³": PressureDimension(
                name="æƒ…å ±ä¸è¶³",
                base_intensity=1.0,
                target_layers={
                    StructuralLayer.PHYSICAL: 0.0,
                    StructuralLayer.BASE: 0.0,
                    StructuralLayer.CORE: 0.2,
                    StructuralLayer.UPPER: 0.8
                }
            )
        }
        
        self.engine = MultidimensionalPressureEngine()
        # åœ§åŠ›æ¬¡å…ƒã‚’ç™»éŒ²
        for name, dimension in self.pressure_dimensions.items():
            self.engine.add_dimension(dimension)
    
    def compute_apex_pressure(self, situation: dict) -> HumanPressure:
        """çŠ¶æ³ã‹ã‚‰æ±ç”¨åœ§åŠ›æ¬¡å…ƒã‚’è¨ˆç®—ã—ã€HumanPressureã«å¤‰æ›"""
        
        # å„åœ§åŠ›æ¬¡å…ƒã®å¼·åº¦ã‚’çŠ¶æ³ã‹ã‚‰è¨ˆç®—
        survival_threat = self._compute_survival_threat(situation)
        competition_pressure = self._compute_competition_pressure(situation) 
        time_urgency = self._compute_time_urgency(situation)
        information_deficit = self._compute_information_deficit(situation)
        
        pressures = {
            "ç”Ÿå­˜è„…å¨": survival_threat,
            "ç«¶äº‰åœ§åŠ›": competition_pressure,
            "æ™‚é–“åˆ‡è¿«": time_urgency,
            "æƒ…å ±ä¸è¶³": information_deficit
        }
        
        # å¤šæ¬¡å…ƒåœ§åŠ›ã‚¨ãƒ³ã‚¸ãƒ³ã§å±¤åˆ¥åœ§åŠ›ã‚’è¨ˆç®—
        self.engine.update_dimension_values(pressures)
        result = self.engine.calculate_layer_pressures()
        
        # HumanPressureã«å¤‰æ›
        return HumanPressure(
            physical=result.layer_pressures[0],
            base=result.layer_pressures[1], 
            core=result.layer_pressures[2],
            upper=result.layer_pressures[3]
        )
    
    def _compute_survival_threat(self, situation: dict) -> float:
        """ç”Ÿå­˜è„…å¨ã®è¨ˆç®—ï¼ˆHPçŠ¶æ…‹ï¼‹é †ä½çŠ¶æ…‹ï¼‰"""
        hp_threat = max(0, (5 - situation['hp']) / 4)  # HPä½ä¸‹ = è„…å¨å¢—å¤§
        rank_threat = max(0, (situation['rank'] - 1) / 6)  # é †ä½ä½ä¸‹ = è„…å¨å¢—å¤§
        
        # éç·šå½¢å¢—å¤§ï¼ˆæŒ‡æ•°é–¢æ•°çš„å±æ©Ÿæ„Ÿï¼‰
        total_threat = hp_threat * 2 + rank_threat
        return min(100.0, total_threat ** 1.5 * 50)
    
    def _compute_competition_pressure(self, situation: dict) -> float:
        """ç«¶äº‰åœ§åŠ›ã®è¨ˆç®—ï¼ˆã‚¹ã‚³ã‚¢å·®ï¼‹ç”Ÿå­˜è€…æ•°ï¼‰"""
        if situation['rank'] == 1:
            # 1ä½: è¿½ã„ä¸Šã’ã‚‰ã‚Œã‚‹ææ€–
            return min(50.0, situation['alive_count'] * 5)
        else:
            # 2ä½ä»¥ä¸‹: è¿½ã„ä¸Šã’ã‚‹å¿…è¦æ€§
            score_gap = situation['leader_score'] - situation['score']
            return min(100.0, score_gap / 10 + situation['rank'] * 5)
    
    def _compute_time_urgency(self, situation: dict) -> float:
        """æ™‚é–“åˆ‡è¿«ã®è¨ˆç®—ï¼ˆæ®‹ã‚Šãƒ©ã‚¦ãƒ³ãƒ‰ï¼‹ã‚»ãƒƒãƒˆï¼‰"""
        round_urgency = (situation['total_rounds'] - situation['round']) / situation['total_rounds']
        set_urgency = (situation['total_sets'] - situation['set']) / situation['total_sets']
        
        # çµ‚ç›¤ã»ã©åˆ‡è¿«æ„Ÿå¢—å¤§
        return (1 - round_urgency * set_urgency) * 80
    
    def _compute_information_deficit(self, situation: dict) -> float:
        """æƒ…å ±ä¸è¶³ã®è¨ˆç®—ï¼ˆä»–ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼æƒ…å ±ã®æœ‰ç„¡ï¼‰"""
        if situation.get('other_players_history'):
            # æƒ…å ±ãŒã‚ã‚‹ = æˆ¦ç•¥çš„æ€è€ƒå¯èƒ½
            return 20.0
        else:
            # æƒ…å ±ä¸è¶³ = ä¸ç¢ºå®Ÿæ€§é«˜
            return 60.0


class ApexPlayerV4:
    """APEX SURVIVOR ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼ˆv4: çœŸã®å‰µç™ºç‰ˆï¼‰
    
    v3ã¨ã®æ ¹æœ¬çš„é•ã„:
    1. äººæ ¼åˆ¥ifæ–‡ã‚’å®Œå…¨æ’é™¤
    2. æ±ç”¨åœ§åŠ›ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹ç†è«–çš„æ„å‘³åœ§
    3. SSDã‚³ã‚¢ã‚¨ãƒ³ã‚¸ãƒ³ã®è·³èºæ©Ÿèƒ½ã‚’çµ±åˆ
    4. å˜ä¸€ã®å‰µç™ºé–¢æ•°ã‹ã‚‰è¡Œå‹•æ±ºå®š
    """
    
    def __init__(self, name: str, initial_kappa_profile: str, color: str):
        self.name = name
        self.initial_kappa_profile = initial_kappa_profile  # personalityã‚’å»ƒæ­¢
        self.color = color
        
        # ã‚²ãƒ¼ãƒ çŠ¶æ…‹
        self.hp = GameConfig.STARTING_HP
        self.score = 0
        self.is_alive = True
        self.choice_history = []
        
        # SSDã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
        params = HumanParams()
        self.agent = HumanAgent(params=params, agent_id=f"Apex_{self.name}", enable_nonlinear_transfer=True)
        
        # æ±ç”¨åœ§åŠ›ã‚¨ãƒ³ã‚¸ãƒ³
        self.pressure_engine = ApexPressureEngine()
        
        # Îºãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«åˆæœŸåŒ–ï¼ˆpersonalityçš„æ„å‘³ã‚’æ’é™¤ã—ã€ç´”ç²‹ã«åˆæœŸæ¡ä»¶ã¨ã—ã¦è¨­å®šï¼‰
        self._initialize_kappa_profile()
    
    def _initialize_kappa_profile(self):
        """Îºãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«åˆæœŸåŒ–ï¼ˆpersonalityæ¦‚å¿µã‚’æ’é™¤ï¼‰
        
        v4ã§ã¯ã€Œæ€§æ ¼ã€ã§ã¯ãªãã€ŒåˆæœŸÎºæ¡ä»¶ã€ã¨ã—ã¦è¨­å®š:
        - é€²åŒ–çš„ãƒ»å­¦ç¿’çš„èƒŒæ™¯ã«ã‚ˆã‚‹å€‹ä½“å·®ã‚’ÎºåˆæœŸå€¤ã§è¡¨ç¾
        - è¡Œå‹•æ±ºå®šãƒ­ã‚¸ãƒƒã‚¯ã¯å…¨å€‹ä½“ã§çµ±ä¸€
        """
        if self.initial_kappa_profile == 'high_survival_threshold':
            # é«˜ç”Ÿå­˜é–¾å€¤å‹: BASEå±¤ã®é–¾å€¤ãŒé«˜ã„ï¼ˆç”Ÿå­˜è„…å¨ã«éˆæ„Ÿï¼‰
            self.agent.state.kappa[HumanLayer.BASE.value] = 150.0
            self.agent.state.kappa[HumanLayer.CORE.value] = 5.0
            self.agent.state.kappa[HumanLayer.UPPER.value] = 15.0
        elif self.initial_kappa_profile == 'high_competition_threshold':
            # é«˜ç«¶äº‰é–¾å€¤å‹: COREå±¤ã®é–¾å€¤ãŒé«˜ã„ï¼ˆç«¶äº‰åœ§åŠ›ã«éˆæ„Ÿï¼‰
            self.agent.state.kappa[HumanLayer.BASE.value] = 100.0
            self.agent.state.kappa[HumanLayer.CORE.value] = 10.0
            self.agent.state.kappa[HumanLayer.UPPER.value] = 20.0
        else:  # balanced_threshold
            # ãƒãƒ©ãƒ³ã‚¹å‹: å„å±¤ã®ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚ŒãŸé–¾å€¤
            self.agent.state.kappa[HumanLayer.BASE.value] = 120.0
            self.agent.state.kappa[HumanLayer.CORE.value] = 7.0
            self.agent.state.kappa[HumanLayer.UPPER.value] = 18.0
        
        # åˆæœŸEå€¤ï¼ˆå…¨ã‚¿ã‚¤ãƒ—ã§çµ±ä¸€ï¼‰
        self.agent.state.E[HumanLayer.BASE.value] = 40.0
        self.agent.state.E[HumanLayer.CORE.value] = 0.5
        self.agent.state.E[HumanLayer.UPPER.value] = 4.0
    
    def make_choice(self, current_rank: int, leader_score: int, round_num: int, 
                    total_rounds: int, alive_count: int, current_set: int, total_sets: int,
                    other_players_history: dict = None) -> int:
        """ç´”ç²‹å‰µç™ºã«ã‚ˆã‚‹é¸æŠæ±ºå®šï¼ˆv4: çµ±ä¸€å‰µç™ºé–¢æ•°ï¼‰"""
        
        if not self.is_alive:
            return 1
        
        # ===== STEP 1: çŠ¶æ³ã‹ã‚‰æ±ç”¨åœ§åŠ›æ¬¡å…ƒã‚’è¨ˆç®— =====
        situation = {
            'hp': self.hp,
            'score': self.score,
            'rank': current_rank,
            'leader_score': leader_score,
            'round': round_num,
            'total_rounds': total_rounds,
            'set': current_set,
            'total_sets': total_sets,
            'alive_count': alive_count,
            'other_players_history': other_players_history
        }
        
        pressure = self.pressure_engine.compute_apex_pressure(situation)
        
        # ===== STEP 2: SSDã‚¨ãƒ³ã‚¸ãƒ³ã§çŠ¶æ…‹æ›´æ–° =====
        self.agent.step(pressure, dt=1.0)
        
        # ===== STEP 3: è·³èºæ¤œå‡º =====
        leap_detected, leap_layer = self.agent.engine.detect_leap(
            self.agent.state, pressure.to_vector()
        )
        
        if leap_detected:
            # è·³èºç™ºç”Ÿ: éé€£ç¶šçš„è¡Œå‹•å¤‰åŒ–
            choice = self._handle_leap_action(leap_layer, situation)
        else:
            # é€šå¸¸çŠ¶æ…‹: E/Îº/Rã‹ã‚‰ã®å‰µç™ºçš„è¡Œå‹•
            choice = self._compute_emergent_action()
        
        self.choice_history.append(choice)
        return choice
    
    def _handle_leap_action(self, leap_layer: int, situation: dict) -> int:
        """è·³èºã«ã‚ˆã‚‹éé€£ç¶šçš„è¡Œå‹•ï¼ˆv4æ–°æ©Ÿèƒ½ï¼‰"""
        
        # è·³èºå±¤ã«å¿œã˜ãŸæ¥µç«¯ãªè¡Œå‹•
        if leap_layer == HumanLayer.BASE.value:
            # BASEå±¤è·³èº: ç”Ÿå­˜æœ¬èƒ½ã®æš´èµ° â†’ æ¥µç«¯ãªå®‰å…¨å¿—å‘
            return 1  # æœ€å®‰å…¨
        elif leap_layer == HumanLayer.CORE.value:
            # COREå±¤è·³èº: ç«¶äº‰æ¬²æ±‚ã®æš´èµ° â†’ æ¥µç«¯ãªæ”»æ’ƒå¿—å‘
            return 10  # æœ€å±é™º
        elif leap_layer == HumanLayer.UPPER.value:
            # UPPERå±¤è·³èº: æˆ¦ç•¥æ€è€ƒã®æš´èµ° â†’ è¨ˆç®—ã•ã‚ŒãŸæ¥µç«¯è¡Œå‹•
            if situation['rank'] == 1:
                return 1  # 1ä½ãªã‚‰å®ˆã‚Šåˆ‡ã‚‹
            else:
                return 9  # ä¸‹ä½ãªã‚‰ä¸€ã‹å…«ã‹
        else:
            # PHYSICALå±¤è·³èº: èº«ä½“çš„é™ç•Œ â†’ ãƒ©ãƒ³ãƒ€ãƒ è¡Œå‹•
            return random.randint(1, 10)
    
    def _compute_emergent_action(self) -> int:
        """E/Îº/Rã‹ã‚‰ã®ç´”ç²‹å‰µç™ºçš„è¡Œå‹•è¨ˆç®—ï¼ˆv4: çµ±ä¸€é–¢æ•°ï¼‰"""
        
        E = self.agent.state.E
        kappa = self.agent.state.kappa
        R = np.array([1000.0, 100.0, 10.0, 1.0])  # æŠµæŠ—å€¤
        
        # ===== æ§‹é€ çš„å½±éŸ¿åŠ›ã®è¨ˆç®— =====
        # å„å±¤ã®ç›¸å¯¾çš„å½±éŸ¿åŠ›: (E - Îº) * R (è² ã®å ´åˆã¯æŠ‘åˆ¶ã¨ã—ã¦æ©Ÿèƒ½)
        influence = (E - kappa) * R
        
        # æ­£ã®å½±éŸ¿ï¼ˆè¡Œå‹•é§†å‹•ï¼‰ã¨è² ã®å½±éŸ¿ï¼ˆè¡Œå‹•æŠ‘åˆ¶ï¼‰ã‚’åˆ†é›¢
        drive = np.maximum(0, influence)  # è¡Œå‹•é§†å‹•åŠ›
        restraint = np.maximum(0, -influence)  # è¡Œå‹•æŠ‘åˆ¶åŠ›
        
        # ===== å±¤åˆ¥è¡Œå‹•ãƒ™ã‚¯ãƒˆãƒ«ã®è¨ˆç®— =====
        # BASE: å®‰å…¨å¿—å‘ï¼ˆå€¤ãŒå¤§ãã„ã»ã©å®‰å…¨ãªé¸æŠï¼‰
        safety_drive = drive[HumanLayer.BASE.value] - restraint[HumanLayer.BASE.value] * 0.5
        
        # CORE: æ”»æ’ƒå¿—å‘ï¼ˆå€¤ãŒå¤§ãã„ã»ã©å±é™ºãªé¸æŠï¼‰
        attack_drive = drive[HumanLayer.CORE.value] - restraint[HumanLayer.CORE.value] * 0.5
        
        # UPPER: æˆ¦ç•¥çš„æœ€é©åŒ–ï¼ˆçŠ¶æ³ã«å¿œã˜ãŸèª¿æ•´ï¼‰
        strategic_drive = drive[HumanLayer.UPPER.value] - restraint[HumanLayer.UPPER.value] * 0.5
        
        # PHYSICAL: èº«ä½“çš„åˆ¶ç´„ï¼ˆæ¥µç«¯ãªè¡Œå‹•ã‚’åˆ¶é™ï¼‰
        physical_constraint = restraint[HumanLayer.PHYSICAL.value]
        
        # ===== çµ±ä¸€å‰µç™ºé–¢æ•° =====
        # åŸºæº–ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ï¼ˆä¸­é–“ç‚¹ï¼‰
        base_risk = 5.0
        
        # å„å±¤ã®å¯„ä¸ã‚’çµ±åˆï¼ˆä¿‚æ•°ã‚’å¤§å¹…èª¿æ•´ï¼‰
        safety_effect = -safety_drive * 0.3   # å®‰å…¨å¿—å‘ = ãƒªã‚¹ã‚¯ä½ä¸‹ï¼ˆå¼·åŒ–ï¼‰
        attack_effect = attack_drive * 0.1    # æ”»æ’ƒå¿—å‘ = ãƒªã‚¹ã‚¯å¢—åŠ ï¼ˆåˆ¶é™ï¼‰
        strategic_effect = strategic_drive * 0.2  # æˆ¦ç•¥èª¿æ•´ï¼ˆå¼·åŒ–ï¼‰
        
        # èº«ä½“åˆ¶ç´„ã«ã‚ˆã‚‹ä¸Šä¸‹é™ï¼ˆåŠ¹æœã‚’å¼·åŒ–ï¼‰
        constraint_factor = 1.0 / (1.0 + physical_constraint * 0.01)
        
        # æœ€çµ‚ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«
        risk_level = base_risk + safety_effect + attack_effect + strategic_effect
        risk_level *= constraint_factor
        
        # æ¥µç«¯å€¤ã®åˆ¶é™ï¼ˆå‰µç™ºçš„èª¿æ•´ï¼‰
        if safety_drive > 50:  # å¼·ã„å®‰å…¨å¿—å‘
            risk_level = min(risk_level, 3.0)
        if attack_drive > 20:  # å¼·ã„æ”»æ’ƒå¿—å‘
            risk_level = max(risk_level, 7.0)
        
        # é¸æŠå€¤ã«å¤‰æ›ï¼ˆ1-10ï¼‰
        choice = max(1, min(10, int(risk_level + 0.5)))
        
        return choice
    
    def process_result(self, choice: int, crashed: bool, score_gained: int):
        """çµæœå‡¦ç†ï¼ˆv4: å­¦ç¿’ã‚‚SSDã‚¨ãƒ³ã‚¸ãƒ³ã«å§”è­²ï¼‰"""
        if not self.is_alive:
            return
        
        # ã‚¹ã‚³ã‚¢æ›´æ–°
        if not crashed:
            self.score += score_gained
        
        # HPæ›´æ–°
        if crashed:
            self.hp -= 1
            if self.hp <= 0:
                self.is_alive = False
        
        # çµæœã‚’SSDã‚¨ãƒ³ã‚¸ãƒ³ã®å­¦ç¿’æ©Ÿæ§‹ã«å§”è­²
        # ï¼ˆv4ã§ã¯å¤–éƒ¨å­¦ç¿’ãƒ­ã‚¸ãƒƒã‚¯ã‚’æ’é™¤ã—ã€ã‚³ã‚¢ã‚¨ãƒ³ã‚¸ãƒ³ã®è‡ªç„¶ãªå­¦ç¿’ã«ä»»ã›ã‚‹ï¼‰
        

def demo_v4_pure_emergence():
    """v4: ç´”ç²‹å‰µç™ºãƒ‡ãƒ¢"""
    print("="*60)
    print("ğŸ§  APEX SURVIVOR v4 - ç´”ç²‹å‰µç™ºãƒ‡ãƒ¢")
    print("="*60)
    
    # ç•°ãªã‚‹Îºãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½œæˆ
    players = [
        ApexPlayerV4("ç”°ä¸­", "high_survival_threshold", "ğŸ”µ"),
        ApexPlayerV4("ä½è—¤", "high_competition_threshold", "ğŸ”´"),
        ApexPlayerV4("éˆ´æœ¨", "balanced_threshold", "ğŸŸ¢")
    ]
    
    # ãƒ†ã‚¹ãƒˆçŠ¶æ³
    test_situations = [
        {
            "name": "åºç›¤å®‰å…¨",
            "hp": 4, "rank": 3, "leader_score": 100, "score": 80,
            "round": 2, "total_rounds": 5, "set": 1, "total_sets": 5,
            "alive_count": 7
        },
        {
            "name": "ä¸­ç›¤å±æ©Ÿ",
            "hp": 2, "rank": 5, "leader_score": 300, "score": 200,
            "round": 4, "total_rounds": 5, "set": 3, "total_sets": 5,
            "alive_count": 5
        },
        {
            "name": "çµ‚ç›¤æ±ºæˆ¦",
            "hp": 3, "rank": 2, "leader_score": 500, "score": 480,
            "round": 5, "total_rounds": 5, "set": 5, "total_sets": 5,
            "alive_count": 3
        }
    ]
    
    for situation in test_situations:
        print(f"\nã€{situation['name']}ã€‘")
        print(f"HP:{situation['hp']}, é †ä½:{situation['rank']}, ã‚®ãƒ£ãƒƒãƒ—:{situation['leader_score']-situation['score']}")
        
        for player in players:
            # ä¸€æ™‚çš„ã«çŠ¶æ³ã‚’è¨­å®š
            player.hp = situation['hp']
            player.score = situation['score']
            
            choice = player.make_choice(
                situation['rank'], situation['leader_score'],
                situation['round'], situation['total_rounds'],
                situation['alive_count'], situation['set'], situation['total_sets']
            )
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿½åŠ 
            E = player.agent.state.E
            kappa = player.agent.state.kappa
            R = np.array([1000.0, 100.0, 10.0, 1.0])
            influence = (E - kappa) * R
            drive = np.maximum(0, influence)
            restraint = np.maximum(0, -influence)
            
            safety_drive = drive[1] - restraint[1] * 0.5
            attack_drive = drive[2] - restraint[2] * 0.5
            strategic_drive = drive[3] - restraint[3] * 0.5
            
            print(f"  {player.name}({player.initial_kappa_profile[:4]}): é¸æŠ={choice}")
            print(f"    E=[{E[1]:.1f}, {E[2]:.1f}, {E[3]:.1f}]")
            print(f"    Îº=[{kappa[1]:.0f}, {kappa[2]:.0f}, {kappa[3]:.0f}]")
            print(f"    Drive: safety={safety_drive:.1f}, attack={attack_drive:.1f}, strategic={strategic_drive:.1f}")


if __name__ == "__main__":
    demo_v4_pure_emergence()